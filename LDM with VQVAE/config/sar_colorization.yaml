dataset_params:
  im_path: 'data/SAR_Dataset'
  im_channels : 3
  im_size : 256
  name: 'sar_colorization'

diffusion_params:
  num_timesteps : 1000
  beta_start : 0.0001
  beta_end : 0.02

ldm_params:
  in_channels: 256
  out_channels: 256
  n_channels: 256
  n_heads: 8
  n_res_blocks: 2
  attention_levels: [0, 1, 2]
  channel_multipliers: [1, 2, 4, 4]
  n_blocks: 2
  time_embedding_dim: 256
  condition_config:
    condition_types: [ 'text', 'image' ]
    text_condition_config:
        text_embed_model: 'clip'
        text_embed_dim: 512
        cond_drop_prob: 0.1
    image_condition_config:
       image_condition_input_channels: 1
       image_condition_output_channels: 3
       image_condition_h : 256
       image_condition_w : 256
       cond_drop_prob: 0.1

autoencoder_params:
  embedding_dim: 256
  n_codes: 2048
  n_filters: 128
  down_sampling_levels: [2, 2, 2, 2]
  n_res_blocks: 2
  z_channels: 256 # This was inferred from ldm_params.in_channels

train_params:
  seed : 1111
  task_name: 'sar_colorization'
  ldm_batch_size: 4
  autoencoder_batch_size: 4
  disc_start: 15000
  disc_weight: 0.5
  codebook_weight: 1
  commitment_beta: 0.2
  perceptual_weight: 1
  ldm_epochs: 100
  autoencoder_epochs: 20
  num_samples: 1
  num_grid_rows: 1
  ldm_lr: 0.0001
  autoencoder_lr: 0.0001
  autoencoder_acc_steps: 1
  autoencoder_img_save_steps: 100
  save_latents : True
  vqvae_latent_dir_name: 'vqvae_latents'
  ldm_ckpt_name: 'ldm.pth'
  vqvae_autoencoder_ckpt_name: 'vqvae.pth'
  vqvae_discriminator_ckpt_name: 'vqvae_discriminator.pth'
  guidance_scale: 7.5
